{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN 기초 예제 - MNIST 문제 해결 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -fr logdir/mnist*\n",
    "!mkdir -p logdir data/mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tf36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/envs/tf36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist.input_data \\\n",
    "    import read_data_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-5ac60e7afb4f>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /opt/conda/envs/tf36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /opt/conda/envs/tf36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /opt/conda/envs/tf36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /opt/conda/envs/tf36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = read_data_sets('data/mnist', one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, (55000, 784), (55000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.num_examples, \\\n",
    "mnist.train.images.shape, \\\n",
    "mnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, (10000, 784), (10000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.num_examples, \\\n",
    "mnist.test.images.shape, \\\n",
    "mnist.test.labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터의 규격 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_UNITS = 28\n",
    "NUM_HIDDEN_UNITS = 31\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "MAX_SEQ_LEN = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 루프 카운트 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(429, 78)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loop_count = mnist.train.num_examples // BATCH_SIZE\n",
    "test_loop_count  = mnist.test.num_examples // BATCH_SIZE\n",
    "\n",
    "train_loop_count, test_loop_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 루프 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    inputs,\n",
    "    labels,\n",
    "    max_epochs,\n",
    "    train_writer=None,\n",
    "    test_writer=None,\n",
    "    mnist=mnist):\n",
    "    \n",
    "    step = 0\n",
    "    for ep in range(max_epochs):\n",
    "\n",
    "        train_elapsed = []\n",
    "        train_losses = []\n",
    "        train_accuracy = []\n",
    "        for i in range(train_loop_count):\n",
    "            t_start     = time.time()\n",
    "            offs        = i * BATCH_SIZE\n",
    "            batch_input = \\\n",
    "                mnist.train.images[offs:offs+BATCH_SIZE,:]\n",
    "            batch_input = \\\n",
    "                batch_input.reshape([BATCH_SIZE,\n",
    "                                        MAX_SEQ_LEN,\n",
    "                                        INPUT_UNITS])\n",
    "            batch_label = \\\n",
    "                mnist.train.labels[offs:offs+BATCH_SIZE]\n",
    "            optimize, loss, accuracy, = \\\n",
    "                sess.run([model.optimize,\n",
    "                          model.loss,\n",
    "                          model.accuracy],\n",
    "                         feed_dict = {\n",
    "                          inputs: batch_input,\n",
    "                          labels: batch_label })\n",
    "            train_losses.append(loss)\n",
    "            train_accuracy.append(accuracy)\n",
    "            t_elapsed   = time.time() - t_start\n",
    "            train_elapsed.append(t_elapsed)\n",
    "\n",
    "            step += 1\n",
    "\n",
    "            if train_writer:\n",
    "                summary = tf.Summary(\n",
    "                    value=[\n",
    "                        tf.Summary.Value(\n",
    "                            tag='accuracy',\n",
    "                            simple_value=accuracy\n",
    "                        ),\n",
    "                        tf.Summary.Value(\n",
    "                            tag='loss',\n",
    "                            simple_value=loss\n",
    "                        ),\n",
    "                    ]\n",
    "                )\n",
    "                train_writer.add_summary(summary,global_step=step)\n",
    "\n",
    "            if step % 250 == 0:\n",
    "                print(('[trn] ep {:d}, step {:d}, ' + \n",
    "                       'loss {:f}, accu {:f}, ' + \n",
    "                       'sec/iter {:f}').format(\n",
    "                    ep + 1,\n",
    "                    step,\n",
    "                    np.mean(train_losses),\n",
    "                    np.amin(train_accuracy),\n",
    "                    np.mean(train_elapsed)))\n",
    "                train_losses = []\n",
    "                train_accuracy = []\n",
    "                train_elapsed = []\n",
    "\n",
    "        test_elapsed  = []\n",
    "        test_accuracy = []\n",
    "        for i in range(test_loop_count):\n",
    "            t_start     = time.time()\n",
    "            offs        = i * BATCH_SIZE\n",
    "            batch_input = \\\n",
    "                mnist.test.images[offs:offs+BATCH_SIZE,:]\n",
    "            batch_input = \\\n",
    "                batch_input.reshape([BATCH_SIZE,\n",
    "                                       MAX_SEQ_LEN,\n",
    "                                       INPUT_UNITS])\n",
    "            batch_label = \\\n",
    "                mnist.test.labels[offs:offs+BATCH_SIZE]\n",
    "            accuracy, = \\\n",
    "                sess.run([model.accuracy],\n",
    "                         feed_dict = {\n",
    "                          inputs: batch_input,\n",
    "                          labels: batch_label })\n",
    "            test_accuracy.append(accuracy)\n",
    "            t_elapsed   = time.time() - t_start\n",
    "            test_elapsed.append(t_elapsed)\n",
    "\n",
    "            step += 1\n",
    "            \n",
    "            if test_writer:\n",
    "                summary = tf.Summary(\n",
    "                    value=[\n",
    "                        tf.Summary.Value(\n",
    "                            tag='accuracy',\n",
    "                            simple_value=accuracy\n",
    "                        ),\n",
    "                    ]\n",
    "                )\n",
    "                test_writer.add_summary(summary,global_step=step)\n",
    "\n",
    "            if step % 250 == 0:\n",
    "                print(('[tst] ep {:d}, ' +\n",
    "                       'step {:d}, accu {:f}, ' + \n",
    "                       'sec/iter {:f}').format(\n",
    "                    ep + 1,\n",
    "                    step,\n",
    "                    np.amin(test_accuracy),\n",
    "                    np.mean(test_elapsed)))\n",
    "                test_accuracy = []\n",
    "                test_elapsed  = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistRnn:\n",
    "    def __init__(self, \n",
    "                 inputs, \n",
    "                 labels, \n",
    "                 input_units, \n",
    "                 num_hidden_units, \n",
    "                 batch_size, \n",
    "                 max_seq_len):\n",
    "        '''\n",
    "        inputs: in shape [batch_size, max_seq_len, input_size]\n",
    "        labels: in shape [batch_size]\n",
    "        '''\n",
    "\n",
    "        # ===>>> MultiRNNCell <<<===\n",
    "        multi_cells     = tf.contrib.rnn.MultiRNNCell([\n",
    "                            tf.contrib.rnn.BasicRNNCell(\n",
    "                                num_hidden_units) \\\n",
    "                            for _ in \\\n",
    "                            range(3) ])\n",
    "\n",
    "        sequence_length = [max_seq_len] * batch_size\n",
    "        last, states    = tf.nn.dynamic_rnn(\n",
    "                            multi_cells, \n",
    "                            inputs, \n",
    "                            sequence_length=sequence_length, \n",
    "                            dtype=tf.float32)\n",
    "        \n",
    "        # 여기서,\n",
    "        # last.shape: [batch_size, max_seq_len, num_hidden_units]\n",
    "        \n",
    "        #####################################################\n",
    "        # MultiRNNCell 을 쓰면 states값이 tensor 의 tuple 이 됨.\n",
    "        # states.shape : ([?, num_hidden_units],...)\n",
    "        #####################################################\n",
    "\n",
    "        print('last.shape', last.get_shape().as_list())\n",
    "        # print('states', states)\n",
    "\n",
    "        # max_seq_len 축으로 0~27 까지 값 중에 \n",
    "        # 0~26 때의 출력 값은 사용하지 않음\n",
    "        rnn_output = last[:,max_seq_len-1,:] \n",
    "        # rnn_output shape: [batch_size, num_hidden_units]\n",
    "        print('rnn_output.shape', rnn_output.get_shape().as_list())\n",
    "\n",
    "        # 10 개의 output units 로 만들 \n",
    "        # FCN (fully-connected-network) 구성\n",
    "        # ==> shape: [batch_size, 10]\n",
    "        outputs    = tf.layers.dense(rnn_output, 10)\n",
    "        print('outputs.shape', outputs.get_shape().as_list())\n",
    "\n",
    "        # loss 함수\n",
    "        loss       = tf.losses.sparse_softmax_cross_entropy(\n",
    "                        labels, outputs)\n",
    "        optimize   = tf.train.AdamOptimizer(learning_rate=0.001). \\\n",
    "                        minimize(loss)\n",
    "\n",
    "        # accuracy\n",
    "        preds    = tf.argmax(outputs, axis=1)\n",
    "        errors   = tf.count_nonzero(labels - preds)\n",
    "        accuracy = 1.0 - tf.cast(errors,tf.float32) / \\\n",
    "                         tf.cast(tf.size(preds),tf.float32)\n",
    "\n",
    "        # 클래스 객체 외부에서 참고할 수 있도록 속성으로 저장\n",
    "        self.outputs        = outputs\n",
    "        self.loss           = loss\n",
    "        self.optimize       = optimize\n",
    "        self.accuracy       = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서플로우 그래프 초기화, Placeholders 정의, 그래프 빌드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last.shape [128, 28, 31]\n",
      "rnn_output.shape [128, 31]\n",
      "outputs.shape [128, 10]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "inputs_ = tf.placeholder( tf.float32, [BATCH_SIZE, MAX_SEQ_LEN, INPUT_UNITS], name='inputs')\n",
    "labels_ = tf.placeholder( tf.int64, [BATCH_SIZE], name='labels')\n",
    "\n",
    "model = MnistRnn(inputs_,\n",
    "                 labels_,\n",
    "                 INPUT_UNITS,\n",
    "                 NUM_HIDDEN_UNITS,\n",
    "                 BATCH_SIZE,\n",
    "                 MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 세션 초기화, 변수 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(gpu_options={'allow_growth':True})\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_writer = tf.summary.FileWriter( 'logdir/mnist-train', graph=tf.get_default_graph())\n",
    "test_writer  = tf.summary.FileWriter( 'logdir/mnist-test', graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trn] ep 1, step 250, loss 0.715128, accu 0.632812, sec/iter 0.016920\n",
      "[tst] ep 1, step 500, accu 0.742188, sec/iter 0.007012\n",
      "[trn] ep 2, step 750, loss 0.399335, accu 0.726562, sec/iter 0.016575\n",
      "[tst] ep 2, step 1000, accu 0.742188, sec/iter 0.006642\n",
      "[trn] ep 3, step 1250, loss 0.299648, accu 0.789062, sec/iter 0.017275\n",
      "[tst] ep 3, step 1500, accu 0.835938, sec/iter 0.006415\n",
      "[trn] ep 4, step 1750, loss 0.244132, accu 0.796875, sec/iter 0.015857\n",
      "[tst] ep 4, step 2000, accu 0.835938, sec/iter 0.006531\n",
      "[trn] ep 5, step 2250, loss 0.219277, accu 0.851562, sec/iter 0.017299\n",
      "[tst] ep 5, step 2500, accu 0.851562, sec/iter 0.007007\n",
      "[trn] ep 6, step 2750, loss 0.188766, accu 0.859375, sec/iter 0.024874\n",
      "[tst] ep 6, step 3000, accu 0.835938, sec/iter 0.006326\n",
      "[trn] ep 7, step 3250, loss 0.172981, accu 0.867188, sec/iter 0.016492\n",
      "[tst] ep 7, step 3500, accu 0.859375, sec/iter 0.006635\n",
      "[trn] ep 8, step 3750, loss 0.157755, accu 0.851562, sec/iter 0.016017\n",
      "[tst] ep 8, step 4000, accu 0.882812, sec/iter 0.005893\n",
      "[trn] ep 9, step 4250, loss 0.145744, accu 0.867188, sec/iter 0.015585\n",
      "[tst] ep 9, step 4500, accu 0.898438, sec/iter 0.007851\n",
      "[trn] ep 10, step 4750, loss 0.141043, accu 0.875000, sec/iter 0.016194\n",
      "[tst] ep 10, step 5000, accu 0.921875, sec/iter 0.005907\n"
     ]
    }
   ],
   "source": [
    "train(inputs_, labels_, 10, train_writer, test_writer, mnist=mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# !tensorboard --ip 0.0.0.0 --logdir ../logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mask_radial(shape, r, inv=False, center=True):\n",
    "    h, w = shape\n",
    "\n",
    "    mask = np.zeros(shape)\n",
    "\n",
    "    if center:\n",
    "        cx = w//2\n",
    "        cy = h//2\n",
    "    else:\n",
    "        cx = 0\n",
    "        cy = 0 # h-1\n",
    "\n",
    "    for x in range(w):\n",
    "        rx = abs(cx - x)\n",
    "        ry = int(np.sqrt(r ** 2 - rx ** 2)) if rx < r else 0\n",
    "        y1 = max(0, cy - ry)\n",
    "        y2 = min(h, cy + ry)\n",
    "        mask[y1:y2,x] = 1.0\n",
    "            \n",
    "    if inv:\n",
    "        mask = 1 - mask\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def mask_random(shape, p, seed=80208700):\n",
    "    h, w = shape\n",
    "    np.random.seed(seed)\n",
    "    mask = (np.random.uniform(size=shape) > p).astype(int)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def apply_mask(image, mask):\n",
    "    orig_dt = None\n",
    "    if np.amax(image) > 1.1:\n",
    "        orig_dt = image.dtype\n",
    "        image = image / 255.0\n",
    "    fft2 = np.fft.fftshift(np.fft.fft2(image[:,:]))\n",
    "    fft2 *= mask\n",
    "    # fix imaginary values\n",
    "    image2 = np.real(np.fft.ifft2(np.fft.ifftshift(fft2[:,:])))\n",
    "    # fix range\n",
    "    image2 = np.minimum(1.0,np.maximum(0.0,image2))\n",
    "    # fix dtype\n",
    "    if orig_dt is not None:\n",
    "        image2 = (image2 * 255).astype(orig_dt)\n",
    "    return image2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 데이터 perturbation (mnist.train.images, mnist.test.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "mnist2 = copy.deepcopy(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = 11.0\n",
    "mask = mask_radial((28,28), radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed 9.608443975448608\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t_start = time.time()\n",
    "for i, data in enumerate(mnist2.train.images):\n",
    "    image = data.reshape([28,28])\n",
    "    image2 = apply_mask(image,mask)\n",
    "    mnist2.train.images[i,:] = image2.reshape([784])\n",
    "t_elapsed = time.time() - t_start\n",
    "print('elapsed',t_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-f669dbdd9f54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m13.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m131\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m132\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_i' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 972x252 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[13.5,3.5])\n",
    "plt.subplot(131)\n",
    "plt.imshow((mnist.train.images[test_i]).reshape([28,28]),cmap='gray',vmin=0.0,vmax=1.0)\n",
    "plt.subplot(132)\n",
    "plt.imshow((mnist2.train.images[test_i]).reshape([28,28]),cmap='gray',vmin=0.0,vmax=1.0)\n",
    "plt.subplot(133)\n",
    "plt.imshow((mnist.train.images[test_i]-mnist2.train.images[test_i]).reshape([28,28]),cmap='gray') #,vmin=0.0,vmax=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서플로우 그래프 초기화, Placeholders 정의, 그래프 빌드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "inputs_ = tf.placeholder( tf.float32, [BATCH_SIZE, MAX_SEQ_LEN, INPUT_UNITS], name='inputs')\n",
    "labels_ = tf.placeholder( tf.int64, [BATCH_SIZE], name='labels')\n",
    "\n",
    "model = MnistRnn(inputs_,\n",
    "                 labels_,\n",
    "                 INPUT_UNITS,\n",
    "                 NUM_HIDDEN_UNITS,\n",
    "                 BATCH_SIZE,\n",
    "                 MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 세션 초기화, 변수 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(gpu_options={'allow_growth':True})\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_writer2 = tf.summary.FileWriter( 'logdir/mnist2-train', graph=tf.get_default_graph())\n",
    "test_writer2  = tf.summary.FileWriter( 'logdir/mnist2-test', graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train(inputs_, labels_, 10, train_writer2, test_writer2, mnist=mnist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!tensorboard --ip 0.0.0.0 --logdir ../logdir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tf36)",
   "language": "python",
   "name": "conda_tf36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
