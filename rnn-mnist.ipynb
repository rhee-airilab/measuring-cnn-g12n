{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN 기초 예제 - MNIST 문제 해결 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -fr logdir/mnist*\n",
    "!mkdir -p logdir data/mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tf36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/envs/tf36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist.input_data \\\n",
    "    import read_data_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-5ac60e7afb4f>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /opt/conda/envs/tf36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /opt/conda/envs/tf36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /opt/conda/envs/tf36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /opt/conda/envs/tf36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = read_data_sets('data/mnist', one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, (55000, 784), (55000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.num_examples, \\\n",
    "mnist.train.images.shape, \\\n",
    "mnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, (10000, 784), (10000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.num_examples, \\\n",
    "mnist.test.images.shape, \\\n",
    "mnist.test.labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터의 규격 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_UNITS = 28\n",
    "NUM_HIDDEN_UNITS = 31\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "MAX_SEQ_LEN = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 루프 카운트 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(429, 78)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loop_count = mnist.train.num_examples // BATCH_SIZE\n",
    "test_loop_count  = mnist.test.num_examples // BATCH_SIZE\n",
    "\n",
    "train_loop_count, test_loop_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 루프 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    inputs,\n",
    "    labels,\n",
    "    max_epochs,\n",
    "    train_writer=None,\n",
    "    test_writer=None,\n",
    "    mnist=mnist):\n",
    "    \n",
    "    step = 0\n",
    "    for ep in range(max_epochs):\n",
    "\n",
    "        train_elapsed = []\n",
    "        train_losses = []\n",
    "        train_accuracy = []\n",
    "        for i in range(train_loop_count):\n",
    "            t_start     = time.time()\n",
    "            offs        = i * BATCH_SIZE\n",
    "            batch_input = \\\n",
    "                mnist.train.images[offs:offs+BATCH_SIZE,:]\n",
    "            batch_input = \\\n",
    "                batch_input.reshape([BATCH_SIZE,\n",
    "                                        MAX_SEQ_LEN,\n",
    "                                        INPUT_UNITS])\n",
    "            batch_label = \\\n",
    "                mnist.train.labels[offs:offs+BATCH_SIZE]\n",
    "            optimize, loss, accuracy, = \\\n",
    "                sess.run([model.optimize,\n",
    "                          model.loss,\n",
    "                          model.accuracy],\n",
    "                         feed_dict = {\n",
    "                          inputs: batch_input,\n",
    "                          labels: batch_label })\n",
    "            train_losses.append(loss)\n",
    "            train_accuracy.append(accuracy)\n",
    "            t_elapsed   = time.time() - t_start\n",
    "            train_elapsed.append(t_elapsed)\n",
    "\n",
    "            step += 1\n",
    "\n",
    "            if train_writer:\n",
    "                summary = tf.Summary(\n",
    "                    value=[\n",
    "                        tf.Summary.Value(\n",
    "                            tag='accuracy',\n",
    "                            simple_value=accuracy\n",
    "                        ),\n",
    "                        tf.Summary.Value(\n",
    "                            tag='loss',\n",
    "                            simple_value=loss\n",
    "                        ),\n",
    "                    ]\n",
    "                )\n",
    "                train_writer.add_summary(summary,global_step=step)\n",
    "\n",
    "            if step % 250 == 0:\n",
    "                print(('[trn] ep {:d}, step {:d}, ' + \n",
    "                       'loss {:f}, accu {:f}, ' + \n",
    "                       'sec/iter {:f}').format(\n",
    "                    ep + 1,\n",
    "                    step,\n",
    "                    np.mean(train_losses),\n",
    "                    np.amin(train_accuracy),\n",
    "                    np.mean(train_elapsed)))\n",
    "                train_losses = []\n",
    "                train_accuracy = []\n",
    "                train_elapsed = []\n",
    "\n",
    "        test_elapsed  = []\n",
    "        test_accuracy = []\n",
    "        for i in range(test_loop_count):\n",
    "            t_start     = time.time()\n",
    "            offs        = i * BATCH_SIZE\n",
    "            batch_input = \\\n",
    "                mnist.test.images[offs:offs+BATCH_SIZE,:]\n",
    "            batch_input = \\\n",
    "                batch_input.reshape([BATCH_SIZE,\n",
    "                                       MAX_SEQ_LEN,\n",
    "                                       INPUT_UNITS])\n",
    "            batch_label = \\\n",
    "                mnist.test.labels[offs:offs+BATCH_SIZE]\n",
    "            accuracy, = \\\n",
    "                sess.run([model.accuracy],\n",
    "                         feed_dict = {\n",
    "                          inputs: batch_input,\n",
    "                          labels: batch_label })\n",
    "            test_accuracy.append(accuracy)\n",
    "            t_elapsed   = time.time() - t_start\n",
    "            test_elapsed.append(t_elapsed)\n",
    "\n",
    "            step += 1\n",
    "            \n",
    "            if test_writer:\n",
    "                summary = tf.Summary(\n",
    "                    value=[\n",
    "                        tf.Summary.Value(\n",
    "                            tag='accuracy',\n",
    "                            simple_value=accuracy\n",
    "                        ),\n",
    "                    ]\n",
    "                )\n",
    "                test_writer.add_summary(summary,global_step=step)\n",
    "\n",
    "            if step % 250 == 0:\n",
    "                print(('[tst] ep {:d}, ' +\n",
    "                       'step {:d}, accu {:f}, ' + \n",
    "                       'sec/iter {:f}').format(\n",
    "                    ep + 1,\n",
    "                    step,\n",
    "                    np.amin(test_accuracy),\n",
    "                    np.mean(test_elapsed)))\n",
    "                test_accuracy = []\n",
    "                test_elapsed  = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistRnn:\n",
    "    def __init__(self, \n",
    "                 inputs, \n",
    "                 labels, \n",
    "                 input_units, \n",
    "                 num_hidden_units, \n",
    "                 batch_size, \n",
    "                 max_seq_len):\n",
    "        '''\n",
    "        inputs: in shape [batch_size, max_seq_len, input_size]\n",
    "        labels: in shape [batch_size]\n",
    "        '''\n",
    "\n",
    "        # ===>>> MultiRNNCell <<<===\n",
    "        multi_cells     = tf.contrib.rnn.MultiRNNCell([\n",
    "                            tf.contrib.rnn.BasicRNNCell(\n",
    "                                num_hidden_units) \\\n",
    "                            for _ in \\\n",
    "                            range(3) ])\n",
    "\n",
    "        sequence_length = [max_seq_len] * batch_size\n",
    "        last, states    = tf.nn.dynamic_rnn(\n",
    "                            multi_cells, \n",
    "                            inputs, \n",
    "                            sequence_length=sequence_length, \n",
    "                            dtype=tf.float32)\n",
    "        \n",
    "        # 여기서,\n",
    "        # last.shape: [batch_size, max_seq_len, num_hidden_units]\n",
    "        \n",
    "        #####################################################\n",
    "        # MultiRNNCell 을 쓰면 states값이 tensor 의 tuple 이 됨.\n",
    "        # states.shape : ([?, num_hidden_units],...)\n",
    "        #####################################################\n",
    "\n",
    "        print('last.shape', last.get_shape().as_list())\n",
    "        # print('states', states)\n",
    "\n",
    "        # max_seq_len 축으로 0~27 까지 값 중에 \n",
    "        # 0~26 때의 출력 값은 사용하지 않음\n",
    "        rnn_output = last[:,max_seq_len-1,:] \n",
    "        # rnn_output shape: [batch_size, num_hidden_units]\n",
    "        print('rnn_output.shape', rnn_output.get_shape().as_list())\n",
    "\n",
    "        # 10 개의 output units 로 만들 \n",
    "        # FCN (fully-connected-network) 구성\n",
    "        # ==> shape: [batch_size, 10]\n",
    "        outputs    = tf.layers.dense(rnn_output, 10)\n",
    "        print('outputs.shape', outputs.get_shape().as_list())\n",
    "\n",
    "        # loss 함수\n",
    "        loss       = tf.losses.sparse_softmax_cross_entropy(\n",
    "                        labels, outputs)\n",
    "        optimize   = tf.train.AdamOptimizer(learning_rate=0.001). \\\n",
    "                        minimize(loss)\n",
    "\n",
    "        # accuracy\n",
    "        preds    = tf.argmax(outputs, axis=1)\n",
    "        errors   = tf.count_nonzero(labels - preds)\n",
    "        accuracy = 1.0 - tf.cast(errors,tf.float32) / \\\n",
    "                         tf.cast(tf.size(preds),tf.float32)\n",
    "\n",
    "        # 클래스 객체 외부에서 참고할 수 있도록 속성으로 저장\n",
    "        self.outputs        = outputs\n",
    "        self.loss           = loss\n",
    "        self.optimize       = optimize\n",
    "        self.accuracy       = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서플로우 그래프 초기화, Placeholders 정의, 그래프 빌드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last.shape [128, 28, 31]\n",
      "rnn_output.shape [128, 31]\n",
      "outputs.shape [128, 10]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "inputs_ = tf.placeholder( tf.float32, [BATCH_SIZE, MAX_SEQ_LEN, INPUT_UNITS], name='inputs')\n",
    "labels_ = tf.placeholder( tf.int64, [BATCH_SIZE], name='labels')\n",
    "\n",
    "model = MnistRnn(inputs_,\n",
    "                 labels_,\n",
    "                 INPUT_UNITS,\n",
    "                 NUM_HIDDEN_UNITS,\n",
    "                 BATCH_SIZE,\n",
    "                 MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 세션 초기화, 변수 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(gpu_options={'allow_growth':True})\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_writer = tf.summary.FileWriter( 'logdir/mnist-train', graph=tf.get_default_graph())\n",
    "test_writer  = tf.summary.FileWriter( 'logdir/mnist-test', graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[trn] ep 1, step 250, loss 0.715128, accu 0.632812, sec/iter 0.016920\n",
      "[tst] ep 1, step 500, accu 0.742188, sec/iter 0.007012\n",
      "[trn] ep 2, step 750, loss 0.399335, accu 0.726562, sec/iter 0.016575\n",
      "[tst] ep 2, step 1000, accu 0.742188, sec/iter 0.006642\n",
      "[trn] ep 3, step 1250, loss 0.299648, accu 0.789062, sec/iter 0.017275\n",
      "[tst] ep 3, step 1500, accu 0.835938, sec/iter 0.006415\n",
      "[trn] ep 4, step 1750, loss 0.244132, accu 0.796875, sec/iter 0.015857\n",
      "[tst] ep 4, step 2000, accu 0.835938, sec/iter 0.006531\n",
      "[trn] ep 5, step 2250, loss 0.219277, accu 0.851562, sec/iter 0.017299\n",
      "[tst] ep 5, step 2500, accu 0.851562, sec/iter 0.007007\n",
      "[trn] ep 6, step 2750, loss 0.188766, accu 0.859375, sec/iter 0.024874\n",
      "[tst] ep 6, step 3000, accu 0.835938, sec/iter 0.006326\n",
      "[trn] ep 7, step 3250, loss 0.172981, accu 0.867188, sec/iter 0.016492\n",
      "[tst] ep 7, step 3500, accu 0.859375, sec/iter 0.006635\n",
      "[trn] ep 8, step 3750, loss 0.157755, accu 0.851562, sec/iter 0.016017\n",
      "[tst] ep 8, step 4000, accu 0.882812, sec/iter 0.005893\n",
      "[trn] ep 9, step 4250, loss 0.145744, accu 0.867188, sec/iter 0.015585\n",
      "[tst] ep 9, step 4500, accu 0.898438, sec/iter 0.007851\n"
     ]
    }
   ],
   "source": [
    "train(inputs_, labels_, 10, train_writer, test_writer, mnist=mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# !tensorboard --ip 0.0.0.0 --logdir ../logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mask_radial(shape, r, inv=False, center=True):\n",
    "    h, w = shape\n",
    "\n",
    "    mask = np.zeros(shape)\n",
    "\n",
    "    if center:\n",
    "        cx = w//2\n",
    "        cy = h//2\n",
    "    else:\n",
    "        cx = 0\n",
    "        cy = 0 # h-1\n",
    "\n",
    "    for x in range(w):\n",
    "        rx = abs(cx - x)\n",
    "        ry = int(np.sqrt(r ** 2 - rx ** 2)) if rx < r else 0\n",
    "        y1 = max(0, cy - ry)\n",
    "        y2 = min(h, cy + ry)\n",
    "        mask[y1:y2,x] = 1.0\n",
    "            \n",
    "    if inv:\n",
    "        mask = 1 - mask\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def mask_random(shape, p, seed=80208700):\n",
    "    h, w = shape\n",
    "    np.random.seed(seed)\n",
    "    mask = (np.random.uniform(size=shape) > p).astype(int)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def apply_mask(image, mask):\n",
    "    orig_dt = None\n",
    "    if np.amax(image) > 1.1:\n",
    "        orig_dt = image.dtype\n",
    "        image = image / 255.0\n",
    "    fft2 = np.fft.fftshift(np.fft.fft2(image[:,:]))\n",
    "    fft2 *= mask\n",
    "    # fix imaginary values\n",
    "    image2 = np.real(np.fft.ifft2(np.fft.ifftshift(fft2[:,:])))\n",
    "    # fix range\n",
    "    image2 = np.minimum(1.0,np.maximum(0.0,image2))\n",
    "    # fix dtype\n",
    "    if orig_dt is not None:\n",
    "        image2 = (image2 * 255).astype(orig_dt)\n",
    "    return image2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 데이터 perturbation (mnist.train.images, mnist.test.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "mnist2 = copy.deepcopy(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = 11.0\n",
    "mask = mask_radial((28,28), radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t_start = time.time()\n",
    "for i, data in enumerate(mnist2.train.images):\n",
    "    image = data.reshape([28,28])\n",
    "    image2 = apply_mask(image,mask)\n",
    "    mnist2.train.images[i,:] = image2.reshape([784])\n",
    "t_elapsed = time.time() - t_start\n",
    "print('elapsed',t_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[13.5,3.5])\n",
    "plt.subplot(131)\n",
    "plt.imshow((mnist.train.images[test_i]).reshape([28,28]),cmap='gray',vmin=0.0,vmax=1.0)\n",
    "plt.subplot(132)\n",
    "plt.imshow((mnist2.train.images[test_i]).reshape([28,28]),cmap='gray',vmin=0.0,vmax=1.0)\n",
    "plt.subplot(133)\n",
    "plt.imshow((mnist.train.images[test_i]-mnist2.train.images[test_i]).reshape([28,28]),cmap='gray') #,vmin=0.0,vmax=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서플로우 그래프 초기화, Placeholders 정의, 그래프 빌드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "inputs_ = tf.placeholder( tf.float32, [BATCH_SIZE, MAX_SEQ_LEN, INPUT_UNITS], name='inputs')\n",
    "labels_ = tf.placeholder( tf.int64, [BATCH_SIZE], name='labels')\n",
    "\n",
    "model = MnistRnn(inputs_,\n",
    "                 labels_,\n",
    "                 INPUT_UNITS,\n",
    "                 NUM_HIDDEN_UNITS,\n",
    "                 BATCH_SIZE,\n",
    "                 MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 세션 초기화, 변수 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(gpu_options={'allow_growth':True})\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_writer2 = tf.summary.FileWriter( 'logdir/mnist2-train', graph=tf.get_default_graph())\n",
    "test_writer2  = tf.summary.FileWriter( 'logdir/mnist2-test', graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train(inputs_, labels_, 10, train_writer2, test_writer2, mnist=mnist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!tensorboard --ip 0.0.0.0 --logdir ../logdir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tf36)",
   "language": "python",
   "name": "conda_tf36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
